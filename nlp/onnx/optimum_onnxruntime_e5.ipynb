{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum[onnxruntime] transformers"
      ],
      "metadata": {
        "id": "2mH_16QLTqtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
        "import onnxruntime as onnxrt\n",
        "from transformers import AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "U4nvFaINbQVn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"intfloat/multilingual-e5-large\"\n",
        "save_directory = \"/tmp/onnx\"\n",
        "\n",
        "original_model = ORTModelForFeatureExtraction.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    export=True\n",
        ")\n",
        "\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "original_model.save_pretrained(save_directory)\n",
        "original_tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "# 3m"
      ],
      "metadata": {
        "id": "ANLgAQrraOT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7d364c-cee2-41c6-f918-c373583df439"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Framework not specified. Using pt to export the model.\n",
            "Using the export variant default. Available variants are:\n",
            "    - default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.1.0+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "Saving external data to one file...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/tmp/onnx/tokenizer_config.json',\n",
              " '/tmp/onnx/special_tokens_map.json',\n",
              " '/tmp/onnx/sentencepiece.bpe.model',\n",
              " '/tmp/onnx/added_tokens.json',\n",
              " '/tmp/onnx/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /tmp/onnx"
      ],
      "metadata": {
        "id": "CuQGeHVocSwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71b86a3-42c0-4a0b-b82a-7af980375401"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.2G\n",
            "-rw-r--r-- 1 root root  716 Feb 28 10:19 config.json\n",
            "-rw-r--r-- 1 root root 534K Feb 28 10:19 model.onnx\n",
            "-rw-r--r-- 1 root root 2.1G Feb 28 10:19 model.onnx_data\n",
            "-rw-r--r-- 1 root root 4.9M Feb 28 10:19 sentencepiece.bpe.model\n",
            "-rw-r--r-- 1 root root  964 Feb 28 10:19 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 1.2K Feb 28 10:19 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  17M Feb 28 10:19 tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qnc6QklpTifR"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "\n",
        "onnxrt_options = onnxrt.SessionOptions()\n",
        "\n",
        "onnxrt_options.execution_mode = onnxrt.ExecutionMode.ORT_SEQUENTIAL\n",
        "onnxrt_options.intra_op_num_threads = multiprocessing.cpu_count()\n",
        "\n",
        "# onnxrt_options.execution_mode = onnxrt.ExecutionMode.ORT_PARALLEL\n",
        "# onnxrt_options.inter_op_num_threads = multiprocessing.cpu_count()\n",
        "\n",
        "onnxrt_options.graph_optimization_level = onnxrt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "onnxrt_options.add_session_config_entry('session.intra_op.allow_spinning', '1')\n",
        "\n",
        "model = ORTModelForFeatureExtraction.from_pretrained(\n",
        "    \"/tmp/onnx\",\n",
        "    session_options=onnxrt_options,\n",
        "    providers=['CPUExecutionProvider']\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/tmp/onnx\")\n",
        "\n",
        "onnx_extractor = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# 6s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Giraffes live in Africa.\"\n",
        "embedding = onnx_extractor(text)"
      ],
      "metadata": {
        "id": "8HDivlTgglym"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embedding[0][0]))\n",
        "print(embedding[0][0][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJBVrnfigrOH",
        "outputId": "1ddaa6a8-5e45-442a-f60f-1febaa57f416"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "[-0.3003837764263153, 0.7525163292884827, -0.5127310752868652, -1.2323561906814575, 1.0537605285644531]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, data_list):\n",
        "      self.data_list = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.data_list[index]\n",
        "\n",
        "text_list = [\"Test One\", \"Test Two\"]\n",
        "text_list = text_list * 500\n",
        "\n",
        "metadata_list = [\"Metadata One\", \"Metadata Two\"]\n",
        "metadata_list = metadata_list * 500\n",
        "\n",
        "dataset = EmbeddingDataset(text_list)\n",
        "\n",
        "# for output in tqdm(onnx_extractor(dataset, batch_size=100), total=len(dataset)):\n",
        "#     pass\n",
        "\n",
        "embeddings_list = []\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for output in onnx_extractor(dataset, batch_size=100):\n",
        "    embeddings_list.extend(output)\n",
        "\n",
        "end_time = datetime.now()\n",
        "\n",
        "print(end_time - start_time)"
      ],
      "metadata": {
        "id": "W-Qb86qlVNnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7999df79-d56a-43d5-a110-72708bc37d1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:00:38.301701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embeddings_list))\n",
        "print(len(embeddings_list[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U_YZl8CN-Lc",
        "outputId": "faf87384-b08f-4b90-9900-edc13a2bf31b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for metadata_item, text_item, embeddings_item in zip(metadata_list[:10], text_list[:10], embeddings_list[:10]):\n",
        "    print(f'{metadata_item} - {text_item} - {embeddings_item[0][:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_oawO3lPbbz",
        "outputId": "de499af7-9984-44d8-9ef9-2950c7d84ec6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata One - Test One - [0.580862820148468, 0.5749151110649109, -0.12789195775985718, -2.678431987762451, 1.2358945608139038]\n",
            "Metadata Two - Test Two - [0.9441616535186768, 0.4838103652000427, -0.3671732544898987, -2.198167562484741, 0.7757053375244141]\n",
            "Metadata One - Test One - [0.580862820148468, 0.5749151110649109, -0.12789195775985718, -2.678431987762451, 1.2358945608139038]\n",
            "Metadata Two - Test Two - [0.9441616535186768, 0.4838103652000427, -0.3671732544898987, -2.198167562484741, 0.7757053375244141]\n",
            "Metadata One - Test One - [0.580862820148468, 0.5749151110649109, -0.12789195775985718, -2.678431987762451, 1.2358945608139038]\n",
            "Metadata Two - Test Two - [0.9441616535186768, 0.4838103652000427, -0.3671732544898987, -2.198167562484741, 0.7757053375244141]\n",
            "Metadata One - Test One - [0.580862820148468, 0.5749151110649109, -0.12789195775985718, -2.678431987762451, 1.2358945608139038]\n",
            "Metadata Two - Test Two - [0.9441616535186768, 0.4838103652000427, -0.3671732544898987, -2.198167562484741, 0.7757053375244141]\n",
            "Metadata One - Test One - [0.580862820148468, 0.5749151110649109, -0.12789195775985718, -2.678431987762451, 1.2358945608139038]\n",
            "Metadata Two - Test Two - [0.9441616535186768, 0.4838103652000427, -0.3671732544898987, -2.198167562484741, 0.7757053375244141]\n"
          ]
        }
      ]
    }
  ]
}